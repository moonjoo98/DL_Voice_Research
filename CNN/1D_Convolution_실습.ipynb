{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYlXIAexPGOX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "label_size = 14\n",
        "mpl.rcParams['xtick.labelsize'] = label_size\n",
        "mpl.rcParams['ytick.labelsize'] = label_size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([0,3,4,5])\n",
        "conv1d_filter = np.array([1,2])"
      ],
      "metadata": {
        "id": "jhmugJ9YPKfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Conv1D_Numpy(Seq, Kernel):\n",
        "    kernel_size = len(Kernel)\n",
        "    Length = len(Seq)\n",
        "\n",
        "    output = []\n",
        "    for i in range(Length-kernel_size+1):\n",
        "        conv = np.dot(Seq[i:i+kernel_size], Kernel)\n",
        "        print(Seq[i:i+kernel_size], \"*\", Kernel, \"=> \", conv)\n",
        "\n",
        "        output.append(conv)\n",
        "\n",
        "    output = np.array(output)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "EBtcgh0jPTRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "output = Conv1D_Numpy(data, conv1d_filter)\n",
        "output"
      ],
      "metadata": {
        "id": "mvn82aisPV1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 1D 컨볼루션 모델을 생성하고 컴파일하는 역할을 합니다.\n",
        "def Conv1D_compile(n_filters, SequenceLength, n_features):\n",
        "    conv_model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv1D(filters=n_filters, # 컨볼루션 레이어에서 사용할 필터(커널)의 수입니다.\n",
        "                               kernel_size=2,\n",
        "                               strides=1,\n",
        "                               padding='valid',\n",
        "                               input_shape=(SequenceLength, n_features), # 입력 시퀀스의 길이와 입력 시퀀스의 특성(또는 차원) 수입니다\n",
        "                               use_bias=False, name='c1d')])\n",
        "\n",
        "    conv_model.compile(loss=tf.losses.MeanAbsoluteError(),\n",
        "                       optimizer=tf.optimizers.Adam(learning_rate=5e-2))\n",
        "\n",
        "    conv_model.summary()\n",
        "\n",
        "    return conv_model\n",
        "\n",
        "\n",
        "# 모델을 학습시키고, 특정 에폭마다 모델의 가중치 변화를 추적하여 시각화하는 역할을 합니다.\n",
        "def Conv1D_Fit_and_PlotWeights(model, X, y, epochs, n_weights, freq=20):\n",
        "    w, loss, mae = [], [], []\n",
        "\n",
        "    for r in range(epochs):\n",
        "        history = model.fit(X, y, verbose=0)\n",
        "        if r%freq==0:\n",
        "\n",
        "            w.append(np.sort(model.layers[0].get_weights()[0].reshape(n_weights)))  # 초기 무작위 가중치.\n",
        "            loss.append(history.history['loss'][0])\n",
        "\n",
        "    w = np.array(w)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8,4))\n",
        "\n",
        "    epoch = np.arange(0,len(w))*20 # 매 20번째 epochs마다 모델의 가중치를 추출하고 기록\n",
        "\n",
        "    for n in range(n_weights):\n",
        "        label = \"w_{} -> {}\".format(n, n+1)\n",
        "        plt.plot(epoch,w[:,n], label=label, linewidth=3)\n",
        "        ax.axhline(n+1, c='gray', linestyle='--')\n",
        "\n",
        "    plt.xlabel(\"epoch\", fontsize=14)\n",
        "    plt.ylabel(\"weights\", fontsize=14)\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1., 1.01), fontsize=14)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "QjLgRSr8PX6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.reshape((1, data.shape[0], 1)) # -> np.array([0,3,4,5]).reshape(1,4,1)과 동일\n",
        "y = output.reshape((1, output.shape[0], 1)) # -> np.array([6,11,14]).reshape(1,3,1)과 동일"
      ],
      "metadata": {
        "id": "HJvq0hrlPaqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn = Conv1D_compile(n_filters=1, SequenceLength=4, n_features=1)"
      ],
      "metadata": {
        "id": "pQ6ztA7kPcYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Conv1D_Fit_and_PlotWeights(model=model_cnn, X=X, y=y,\n",
        "                                     epochs=500, n_weights=2)"
      ],
      "metadata": {
        "id": "n8mv1vR7Pe9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p_512K6gxCo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 음성 데이터 1D Convolution 적용 예제"
      ],
      "metadata": {
        "id": "1HmdvmaLdP1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 무작위 데이터 생성\n",
        "batch_size, channels, length = 1, 1, 8000  # 1초 분량의 샘플링 레이트를 8000HZ\n",
        "x_pytorch = torch.randn(batch_size, channels, length)\n",
        "\n",
        "# Conv1D 층 정의\n",
        "conv1d_pytorch = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1) # 16개의 채널 추가 생성\n",
        "\n",
        "# Conv1D 적용\n",
        "output_pytorch = conv1d_pytorch(x_pytorch)\n",
        "\n",
        "print(\"음성 데이터 출력 형태:\", x_pytorch.shape)\n",
        "print(\"----------------------------------------------------\")\n",
        "print(\"PyTorch Conv1D 출력 형태:\", output_pytorch.shape)"
      ],
      "metadata": {
        "id": "g_PkScupWgQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 무작위 데이터 생성\n",
        "x_tensorflow = tf.random.normal((batch_size, length, channels))\n",
        "\n",
        "# Conv1D 층 정의 및 적용\n",
        "conv1d_tensorflow = tf.keras.layers.Conv1D(filters=16, kernel_size=3, strides=1, padding=\"same\")\n",
        "output_tensorflow = conv1d_tensorflow(x_tensorflow)\n",
        "\n",
        "print(\"음성 데이터 출력 형태:\", x_tensorflow.shape)\n",
        "print(\"----------------------------------------------------\")\n",
        "print(\"TensorFlow Conv1D 출력 형태:\", output_tensorflow.shape)"
      ],
      "metadata": {
        "id": "2XZVHLCLxYou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 실제 음성 데이터 멜 스펙토그램 변환"
      ],
      "metadata": {
        "id": "KBTok3m8nAeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "file_path = './213_003_1219.wav'\n",
        "\n",
        "# 10초 길이의 8000Hz 샘플링 레이트 음성 데이터 로드\n",
        "y, sr = librosa.load(file_path, sr=8000, duration=12)\n",
        "\n",
        "# 멜 스펙트로그램을 계산합니다.\n",
        "mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, hop_length=256, n_fft=512)\n",
        "mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
        "\n",
        "# 멜 스펙트로그램의 형태를 확인합니다.\n",
        "print(mel_spectrogram_db.shape)\n",
        "\n",
        "# 멜 스펙트로그램을 시각적으로 그립니다.\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(mel_spectrogram_db, sr=sr, hop_length=256, x_axis='time', y_axis='mel')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('Mel Spectrogram')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ii4UcDigdefy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 멜 스펙토그램에 conv 1d 적용"
      ],
      "metadata": {
        "id": "J3H1BqdknIkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mel_spectrogram_tensor = torch.tensor(mel_spectrogram_db[np.newaxis, :], dtype=torch.float)\n",
        "\n",
        "# 컨볼루션 레이어 정의\n",
        "conv1d_layer = nn.Conv1d(in_channels=128, out_channels=32, kernel_size=3, stride=1, padding=1) # in_channels = input 데이터 채널의 수\n",
        "\n",
        "# 레이어에 멜 스펙트로그램 텐서를 적용합니다. PyTorch는 (batch, channels, length) 형태를 입력해야 합니다.\n",
        "# 우리의 데이터는 (1, 128, length) 형태로, 128은 멜 빈의 수, length는 시간 축에 대한 길이입니다.\n",
        "conv_output = conv1d_layer(mel_spectrogram_tensor)\n",
        "\n",
        "# 결과의 형태를 출력합니다.\n",
        "print('Conv1d Output Shape:', conv_output.shape)\n",
        "\n",
        "# 멜 스펙트로그램을 시각적으로 그립니다.\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(mel_spectrogram_db, sr=sr, hop_length=256, x_axis='time', y_axis='mel')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('Mel Spectrogram')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PHxU1lCoeClg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# groups 추가\n",
        "conv1d_layer = nn.Conv1d(in_channels=128, out_channels=32, kernel_size=3, stride=1, padding=1, groups=4)\n",
        "\n",
        "# 레이어에 멜 스펙트로그램 텐서를 적용합니다.\n",
        "conv_output = conv1d_layer(mel_spectrogram_tensor)\n",
        "\n",
        "# 결과의 형태를 출력합니다.\n",
        "print('Conv1d Output Shape with groups=4:', conv_output.shape)"
      ],
      "metadata": {
        "id": "X9JpVJNIlwut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Depthwise 컨볼루션을 위한 Conv1d 레이어 정의\n",
        "# 입력 채널 수와 출력 채널 수가 동일하고, groups가 in_channels와 같습니다.\n",
        "conv1d_layer_depthwise = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1, groups=128)\n",
        "\n",
        "# 레이어에 멜 스펙트로그램 텐서를 적용합니다.\n",
        "conv_output_depthwise = conv1d_layer_depthwise(mel_spectrogram_tensor)\n",
        "\n",
        "# 결과의 형태를 출력합니다.\n",
        "print('Depthwise Conv1d Output Shape:', conv_output_depthwise.shape)"
      ],
      "metadata": {
        "id": "NUjAYJwVnrg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A9W51Wg_o6Ap"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}